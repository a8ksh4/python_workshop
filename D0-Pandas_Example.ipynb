{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D0 - Pandas Example\n",
    "\n",
    "Feedback: https://forms.gle/Le3RAsMEcYqEyswEA\n",
    "\n",
    "The name \"Pandas\" comes from \"Panel Data\" and \"Python Data Analysis\". \"Panel Data\" refers to two dimensoinal data, often including measurements over time - time series - or collections of things/events. The term \"Pandas\" is a blend of these concepts, reflecting the library's purpose of providing data structures and data analysis tools in Python.\n",
    "\n",
    "**Pandas** are playfull and memorable, just like **Pandas**!\n",
    "\n",
    "Pandas has two types of objects, **DataFrames** and **Series**.  A dataframe has rows and columns, like a spreadsheet - two dimensional.  A single row or column from a dataframe is a Series.  If we select a single column from a DataFrame, we get a series, a single dimensional object, and a series can be inserted into a df column. \n",
    "\n",
    "By convention, we'll import pandas as \"pd\" to save us some typing.\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "**This notebook has an example workflow of importing some data into a pandas dataframe and then graphing it** to get a feel for how things work with pandas.  Don't worry if not everything here makes sense.  **The D1 and following notebooks will go through everything in detail.**\n",
    "\n",
    "So let's see what we dan do with a list of metiorites from Nasa.  The data is is pretty clean (no missing values, bad data, etc), so it doesn't require much cleaning/prep to use.  It shouldn't take too many steps to make some nice plots and make some observtions.\n",
    "\n",
    "First thing is importing.  We use requests to query the url, get the json data, and convert it to a **dataframe**.  A few useful funtions for viewing data in a dataframe are .head(), .tail(), and .info().  \n",
    "\n",
    "*There's more info on this meteorite dataset here: https://data.nasa.gov/Space-Science/Meteorite-Landings/gh4g-9sfh/about_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "# meteorites = requests.get('https://data.nasa.gov/resource/y77d-th95.json').json()\n",
    "meteorites = requests.get('https://raw.githubusercontent.com/a8ksh4/python_workshop/refs/heads/main/SAMPLE_DATA/y77d-th95.json').json()\n",
    "mets = pd.DataFrame(meteorites)\n",
    "mets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we have geolocation, mass, and datetime info for each meteor.  Let's try graphing mass per date to see if there's any obvious trend. \n",
    "\n",
    "We need each column to be the correct datatype before we can generate a plot.\n",
    "* To simplify the datetime 'year' column, we use a string operation to split it on the 'T' ang take just the year, month and day.  Then we can use pd.to_datetime do convert it to a datetime object by passing in the format to use to convert it. Info on datetime conversion: https://www.w3schools.com/python/gloss_python_date_format_codes.asp\n",
    "* We need the mass to be a numeric value so we overwrite the column with itself converted using pd.to_numeric.  Similarly, there ar pd.to_int, pd.to_float, pd.to_string operatoins that we might want to use in other cases. \n",
    "\n",
    "Finally, pandas has a built in plot function that can generate a bunch of different graph types. Setting 'logy' says to graph the y axis in log scale. **Try changing logy between True/False and see what happens to the data points and y axis scale.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the meteorites by date and mass\n",
    "mets['ymd'] = mets['year'].str.split('T').str[0]\n",
    "mets['ymd'] = pd.to_datetime(mets['ymd'], format='%Y-%m-%d', errors='coerce')\n",
    "mets['mass'] = pd.to_numeric(mets['mass'])\n",
    "mets.plot.scatter(x='ymd', y='mass', logy=True, title='Meteorite Mass by Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's neat, but doesn't show much of a trend except that we probably have better records of meteorites found since the late 1800s.  Maybe it would be interesting to see where on earth we are finding the meteorites.  \n",
    "\n",
    "Let's plot them on a map of the earth.  First thing for that is to get a map of the earth.  We can use some geopandas stuff for that.  Below, \"world\" is a dataframe with rows for each landmass on a map.  **Try printing world.head() to see some of the actual data.**  The geometry column has a polygon with a list of points making the shape of each continent.\n",
    "\n",
    "https://geopandas.org/en/stable/docs/user_guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from geodatasets import get_path\n",
    "\n",
    "path = get_path(\"naturalearth.land\")\n",
    "world = geopandas.read_file(path)\n",
    "world.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now lets put it together!  Plotting can get complicated fast... I think that's a weakness of this stuff in python with the pandas, matplotlib libraries, but it's very powerful at least. \n",
    "\n",
    "To combine plots, we initialize an axis that we pass to the .plot function when we call it for the world and our meteorite dataframes so that the can draw themselves on the same graph. 'ax=ax' looks a littele weird.  We'r passing a variable named ax to an argument with the same name.  It's just sort of convention to do it this way.  Maybe it would be better to use axis for the variable name and pass that to the plot function. \n",
    "\n",
    "Often when we import data, numeric columns will be imported as string data, so we need to convert the reclong and reclat (longitude and latitude) to numeric values to plot them.  **We use .astype(float) to do a type conversion from string to float.**\n",
    "\n",
    "**Try changing the colormap** - if you put in a bad value, it'll print a bunch of valid color maps you can try in the error message.  Also note that the norm=... is to convert the mass to log scale here so that we get nice colors for all of the meteorite masses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))           # create a figure and axis\n",
    "\n",
    "world.plot(ax=ax)                                # plot the world on the axis\n",
    "\n",
    "mets['reclong'] = mets['reclong'].astype(float)  # convert reclong column from string to float\n",
    "mets['reclat'] = mets['reclat'].astype(float)    # convert reclat column from string to float\n",
    "\n",
    "# plot the meteorites on the same axis\n",
    "mets.plot(x=\"reclong\", y=\"reclat\", kind=\"scatter\", \n",
    "        c=\"mass\", colormap=\"Accent_r\", \n",
    "        title=f\"Meteors around the world!\", \n",
    "        ax=ax, norm=matplotlib.colors.LogNorm())\n",
    "\n",
    "ax.grid(True)                                   # turn on the grid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's neat.  I extected to see more concentration around the equator.  We might need to normalize for population density (people who could see and find an asteroid to report on) to get an idea of were most asteroids actually fall.  There is a larger version of this dataset at: \n",
    "\n",
    "We'll look at more actual numerical analysis stuff in Week 4.\n",
    "\n",
    "#### *Exercise*\n",
    "Open a new notebook and download the dataset for observed meteors from here: https://www.kaggle.com/datasets/ramjasmaurya/fireballsbolides-1988-april-2022.  Save it in the same directory as your notebook.  If you're working in Google Colab, you should be able to go to File -> Locate notebook in Drive, and then upload the dataset csv file to the same directory in Google drive. \n",
    "\n",
    "Copy over the following code to get started, and use the above example for the meteorites to make a couple of graphs for this new dataset.\n",
    "* radiated energy vs time\n",
    "* altitude vs radiated energy\n",
    "* try using .corr(numeric_only=True) on the dataframe to see which numeric columns have the strongest correlation.   What can we say about these boloids when they enter our atmosphere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = 'nasas fireballs.csv'\n",
    "nfb = pd.read_csv(csv_file_name)\n",
    "# nfb.head() # Uncomment to see the first few rows of the data\n",
    "# nfb.info() # Uncomment to see the column names and data types of each column\n",
    "\n",
    "# the date/time ... column is a string that we want to convert to a datetime object\n",
    "# we're creating a 'date' column for this.  We could also overwrite the existing column\n",
    "# nfb['date'] = pd.to_datetime(nfb['date/time for peak brightness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### *Exercise*\n",
    "Go through some of these datasets and find something that looks interesting to you that we can work on in the following notebooks. \n",
    "\n",
    "* https://github.com/jdorfman/awesome-json-datasets - we can direcly query these using requests and the url as we did for the meteorite data. \n",
    "* https://catalog.data.gov/dataset/\n",
    "* https://data.fivethirtyeight.com/ - they have zip files with csv data\n",
    "* https://www.kaggle.com/datasets - click all data sets and you'll see loads of stuff.  looks like they have large csv files to download.\n",
    "\n",
    "At the end of the Pandas series of notebooks, you should be able to prepare and analyze some data that you find interesting.  So spend some time finding data that's interesting to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
