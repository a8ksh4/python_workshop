{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D2 - Data Cleaning with Pandas\n",
    "\n",
    "Topics:\n",
    "* Setting column data types\n",
    "* Dropping rows with NaN values\n",
    "* Removoing rows with invalid values. \n",
    "\n",
    "Sometimes you'll need to pre-process your data before you can analyze it or present it for analysis. A few scenarios:\n",
    "* Excluding rows or columns with missing or invalid data:\n",
    "  * You have a dataset os several measurments made on many samples.  Some of the samples don't have all measurements done, so you need to exclude them.  You can use dropna to remove rows or columns that are missing the needed measurements. \n",
    "  * Some samples have negative values reported, but this is impossible and would have been the result of a transcription error. We can exclude these rows. \n",
    "\n",
    "* Interpolation:\n",
    "  * You have time series data collected at irregular intervals and need to interpolate it to a regular interval. \n",
    "  * You have spectoscopy data for many samples that are measured at regular but not precise wavelengths for each sample, and you need to interpolate each sample so the wavelengths all align.\n",
    "* Filling Gaps in data\n",
    "  * You have time series data with small gaps - you dan forward fill, backward fill, \n",
    "* Smoothing out noise in data\n",
    "  * It is common to use a rolling median to smooth out an analog signal - it might be noisy from second to second, but a rolling median over 20 seconds will smooth it. Often the noise is from the mesurement and not the sample, so the noise should be removed.\n",
    "  * If you have low frequency, e.g. tidal, data with regular high frequency noise in it, you can use a butterworth filter to exclude the high freqency signal (low pass filter) and preserve the signal you want to analyse.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Duration Pulse Maxpulse Calories\n",
      "0       60   110      130    409.1\n",
      "1       60   117      145    479.0\n",
      "    Duration Pulse Maxpulse Calories\n",
      "169       75   125      150    330.4\n",
      "170        a     b        c        d\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 171 entries, 0 to 170\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Duration  170 non-null    object\n",
      " 1   Pulse     170 non-null    object\n",
      " 2   Maxpulse  170 non-null    object\n",
      " 3   Calories  166 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/a8ksh4/python_workshop/main/SAMPLE_DATA/pulse_calories_modified.csv')\n",
    "df = pd.read_csv('./SAMPLE_DATA/pulse_calories_modified.csv')\n",
    "print(df.head(2))\n",
    "print(df.tail(2))\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting correct data type for columns\n",
    "Right now, df.info is reporting a data type of \"object\" for all columns.  Also note the invalid string characters in df.tail output.  We can use `.astype(...)` to convert the data to numeric.  astype will raise an exception if any of the values in the column(s) cannot be converted to the given data type(s).  When this happens, we can either identify and fix those values first or we can include `errors='ignore'` as an argument. \n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html\n",
    "\n",
    "#### *Exercise*\n",
    "Run the folowing cell to convert the columns to numerc data types and modify it as needed resolve the error from astype.  Add a print statement for df_numeric.info to verify the new data types of each of the columns.\n",
    "What happenend to the string values in the last row of the dataframe?\n",
    "\n",
    "Also take note of the different usage examples commented out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>145</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>60</td>\n",
       "      <td>-115</td>\n",
       "      <td>145</td>\n",
       "      <td>310.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>320.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>75</td>\n",
       "      <td>125</td>\n",
       "      <td>150</td>\n",
       "      <td>330.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Duration Pulse Maxpulse Calories\n",
       "166       60   110      145    300.0\n",
       "167       60  -115      145    310.2\n",
       "168       75   120      150    320.4\n",
       "169       75   125      150    330.4\n",
       "170        a     b        c        d"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single column method:\n",
    "# df['Duration'] = df['Duration'].astype('int')\n",
    "\n",
    "# Multiple columns method:\n",
    "# df = df.astype('float')\n",
    "\n",
    "# Multiplue columns method:\n",
    "df_numeric = df.astype({'Duration': 'int', \n",
    "                'Pulse': 'int', \n",
    "                'Maxpulse': 'int', \n",
    "                'Calories': 'float'}, \n",
    "                errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the string values we want to drop are still inculded, we can try using to_numeric rather than astype.  To_numeric accepts an option, errors='coerce', that will tell it to convert incompatible values to NaN rather than preserving the invalid value as astype does. \n",
    "\n",
    "But to_numeric works only on series data (a single column), so we need to do it once per column or use .apply to run it against all columns. \n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html#pandas.to_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I didn't know about .apply, I would use this to convert each column:\n",
    "# df_numeric = df.copy()\n",
    "# for col in df_numeric.columns:\n",
    "#     df_numeric[col] = pd.to_numeric(df_numeric[col], errors='coerce')\n",
    "\n",
    "# But this is much more efficient, and in the spirit of how pandas is intended to be used:\n",
    "df_numeric = df.apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helpful way to see what was changed is to make a mask indicating which rows in df_numeric have NaN values now, and use the mask to see the original rows still preserved in df. Below, .isnull() returns a boolean dataframe of the same shape as the df it's called against with true/false indicating if each cell is NaN.  And .any looks along the given axis and reports true for any row that has a true in it, returning a series object that we use as a mask.  axis=1 means check each row, and axis=0 would mean check each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Duration  Pulse Maxpulse Calories\n",
      "8        NaN    109      133    195.1\n",
      "17        45     90      112      NaN\n",
      "27        60    103      132      NaN\n",
      "91        45    107      137      NaN\n",
      "118       60    105      125      NaN\n",
      "135       20    NaN      156    189.0\n",
      "141       60     97      127      NaN\n",
      "146       60    107      NaN    400.0\n",
      "153    'foo'  'bar'    'bla'    'asd'\n",
      "170        a      b        c        d\n"
     ]
    }
   ],
   "source": [
    "# print rows which will cause errors in astype conversoin to numeric types:\n",
    "numeric_na_rows = df_numeric.isnull().any(axis=1)\n",
    "print(df[numeric_na_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing rows with NaN values\n",
    "Now that we have only numeric values and NaN values, we can pretty simply call df.dropna() to drop rows (or cols if we specify the axis argument) that have a NaN in them.  \n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "\n",
    "#### *Exescise*:\n",
    "Run df_numeric.dropna() in the following cell and use .info() to see how many rows we are left with.  How many were removed from the original df dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying bad data analytically\n",
    "We have a bunch of numeric data in our dataframe now, but we might want to sanity check that it looks correct.  After all, our interns who transcribed this data are overworked, underpaid, and distracted, so there could be mistakes. \n",
    "\n",
    "#### *Exercise*:\n",
    "Use masks to identify data meeting each of the following conditions.  Print and remove the identified rows from our dataset:\n",
    "* Rows with Pulse or Maxpulse <30 or >220, as these would be impossible for normal humans\n",
    "* Rows with Pulse greater than Maxpulse, as the average can't possibly be greater than the max observed\n",
    "* Duration or Calories < 0 as this is not possible\n",
    "\n",
    "Remember that `~mask` is the inverse of mask, so if your mask matches the condition you want to remove, then you want to set your dataframe to `df[~mask]` to remove the rows that met the criteria.\n",
    "\n",
    "You can check each condition on by one, or you could check them in a loop and in each iteration of the loop, \"or\" the previous mask and new mask together with \"|\" (the pipe symbol).  Then after the loop, your mask will include all of the conditions and you can remove all matching rows at once from df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "foo = ...\n",
    "df_numeric = df_numeric[foo]\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahother thing we can do is check that the calories burned per unit time are reasonable.  We'll do this by calculating normalized calories per duration and identifying outliers which are more than two standard deviations from the average:\n",
    "\n",
    "#### *Exercise*\n",
    "* Create a \"NormalizedCalories\" column equal to Calories divided by Duration\n",
    "* Calculate the average and standard deviation of this new column.  \n",
    "* Create a mask for abs(NormalizedCalories - Average) > (2 * Stdev)\n",
    "* Print the rows identified and remove them from the dataset.  Does this seem like a reasonable filter for outliers?\n",
    "\n",
    "A couple helpful functions you can use for this are:\n",
    "* np.abs(...) to calculate the absolute value\n",
    "* df['col_name'].describe() will return a **dictionary** of statistics describing the column.  You can use 'std' and 'mean' from this dictionary for the standard deviation and the average.  Try printing it to see what all is included. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# your code here:\n",
    "df['NormalizedCalories'] = ...\n",
    "stats = df['NormalizedCalories'].describe()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting data type of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inerpolatoin of time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with missing values\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
